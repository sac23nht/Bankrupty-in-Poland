{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Improve bankruptcy model using gradient boosting\n",
    "* Evaluate Model using precision and recall\n",
    "* Create an interactive dashboard\n",
    "* Create a python module to store the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from IPython.display import VimeoVideo\n",
    "from ipywidgets import interact\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from teaching_tools.widgets import ConfusionMatrixWidget\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filename):\n",
    "     # Open compressed file, load into dictionary\n",
    "    with gzip.open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "     \n",
    "    # Load dictionary into DataFrame, set index\n",
    "    df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9977, 65)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "      <th>bankrupt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174190</td>\n",
       "      <td>0.41299</td>\n",
       "      <td>0.14371</td>\n",
       "      <td>1.3480</td>\n",
       "      <td>-28.9820</td>\n",
       "      <td>0.60383</td>\n",
       "      <td>0.219460</td>\n",
       "      <td>1.12250</td>\n",
       "      <td>1.1961</td>\n",
       "      <td>0.46359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163960</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.83604</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.7145</td>\n",
       "      <td>6.2813</td>\n",
       "      <td>84.291</td>\n",
       "      <td>4.3303</td>\n",
       "      <td>4.0341</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.46038</td>\n",
       "      <td>0.28230</td>\n",
       "      <td>1.6294</td>\n",
       "      <td>2.5952</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>1.17210</td>\n",
       "      <td>1.6018</td>\n",
       "      <td>0.53962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.90108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.9882</td>\n",
       "      <td>4.1103</td>\n",
       "      <td>102.190</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>5.9500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.22612</td>\n",
       "      <td>0.48839</td>\n",
       "      <td>3.1599</td>\n",
       "      <td>84.8740</td>\n",
       "      <td>0.19114</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>2.98810</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>0.67566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.99236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.7742</td>\n",
       "      <td>3.7922</td>\n",
       "      <td>64.846</td>\n",
       "      <td>5.6287</td>\n",
       "      <td>4.4581</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.188290</td>\n",
       "      <td>0.41504</td>\n",
       "      <td>0.34231</td>\n",
       "      <td>1.9279</td>\n",
       "      <td>-58.2740</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.233580</td>\n",
       "      <td>1.40940</td>\n",
       "      <td>1.3393</td>\n",
       "      <td>0.58496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176480</td>\n",
       "      <td>0.321880</td>\n",
       "      <td>0.82635</td>\n",
       "      <td>0.073039</td>\n",
       "      <td>2.5912</td>\n",
       "      <td>7.0756</td>\n",
       "      <td>100.540</td>\n",
       "      <td>3.6303</td>\n",
       "      <td>4.6375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.55615</td>\n",
       "      <td>0.32191</td>\n",
       "      <td>1.6045</td>\n",
       "      <td>16.3140</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.182060</td>\n",
       "      <td>0.79808</td>\n",
       "      <td>1.8126</td>\n",
       "      <td>0.44385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555770</td>\n",
       "      <td>0.410190</td>\n",
       "      <td>0.46957</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>8.4553</td>\n",
       "      <td>3.3488</td>\n",
       "      <td>107.240</td>\n",
       "      <td>3.4036</td>\n",
       "      <td>12.4540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feat_1   feat_2   feat_3  feat_4   feat_5   feat_6    feat_7  \\\n",
       "company_id                                                                   \n",
       "1           0.174190  0.41299  0.14371  1.3480 -28.9820  0.60383  0.219460   \n",
       "2           0.146240  0.46038  0.28230  1.6294   2.5952  0.00000  0.171850   \n",
       "3           0.000595  0.22612  0.48839  3.1599  84.8740  0.19114  0.004572   \n",
       "5           0.188290  0.41504  0.34231  1.9279 -58.2740  0.00000  0.233580   \n",
       "6           0.182060  0.55615  0.32191  1.6045  16.3140  0.00000  0.182060   \n",
       "\n",
       "             feat_8  feat_9  feat_10  ...   feat_56   feat_57  feat_58  \\\n",
       "company_id                            ...                                \n",
       "1           1.12250  1.1961  0.46359  ...  0.163960  0.375740  0.83604   \n",
       "2           1.17210  1.6018  0.53962  ...  0.027516  0.271000  0.90108   \n",
       "3           2.98810  1.0077  0.67566  ...  0.007639  0.000881  0.99236   \n",
       "5           1.40940  1.3393  0.58496  ...  0.176480  0.321880  0.82635   \n",
       "6           0.79808  1.8126  0.44385  ...  0.555770  0.410190  0.46957   \n",
       "\n",
       "             feat_59  feat_60  feat_61  feat_62  feat_63  feat_64  bankrupt  \n",
       "company_id                                                                   \n",
       "1           0.000007   9.7145   6.2813   84.291   4.3303   4.0341     False  \n",
       "2           0.000000   5.9882   4.1103  102.190   3.5716   5.9500     False  \n",
       "3           0.000000   6.7742   3.7922   64.846   5.6287   4.4581     False  \n",
       "5           0.073039   2.5912   7.0756  100.540   3.6303   4.6375     False  \n",
       "6           0.029421   8.4553   3.3488  107.240   3.4036  12.4540     False  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wrangle(\"poland-bankruptcy-data-2009.json.gz\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (9977, 64)\n",
      "y shape: (9977,)\n"
     ]
    }
   ],
   "source": [
    "target = \"bankrupt\"\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7981, 64)\n",
      "y_train shape: (7981,)\n",
      "X_test shape: (1996, 64)\n",
      "y_test shape: (1996,)\n"
     ]
    }
   ],
   "source": [
    "# Divide into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_over shape: (15194, 64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_55</th>\n",
       "      <th>feat_56</th>\n",
       "      <th>feat_57</th>\n",
       "      <th>feat_58</th>\n",
       "      <th>feat_59</th>\n",
       "      <th>feat_60</th>\n",
       "      <th>feat_61</th>\n",
       "      <th>feat_62</th>\n",
       "      <th>feat_63</th>\n",
       "      <th>feat_64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.279320</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>0.852030</td>\n",
       "      <td>17.0440</td>\n",
       "      <td>199.080</td>\n",
       "      <td>0.741770</td>\n",
       "      <td>0.353570</td>\n",
       "      <td>16.00600</td>\n",
       "      <td>1.2346</td>\n",
       "      <td>0.84997</td>\n",
       "      <td>...</td>\n",
       "      <td>52857.00</td>\n",
       "      <td>0.190040</td>\n",
       "      <td>0.328630</td>\n",
       "      <td>0.80996</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1858</td>\n",
       "      <td>11.002</td>\n",
       "      <td>33.1760</td>\n",
       "      <td>18.5720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.735120</td>\n",
       "      <td>0.156460</td>\n",
       "      <td>1.2269</td>\n",
       "      <td>-10.837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.36032</td>\n",
       "      <td>1.4809</td>\n",
       "      <td>0.26488</td>\n",
       "      <td>...</td>\n",
       "      <td>440.02</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.99803</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.4268</td>\n",
       "      <td>2.2925</td>\n",
       "      <td>169.960</td>\n",
       "      <td>2.1476</td>\n",
       "      <td>9.6185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113940</td>\n",
       "      <td>0.490250</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>1.2332</td>\n",
       "      <td>-43.184</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.113940</td>\n",
       "      <td>1.03980</td>\n",
       "      <td>1.1649</td>\n",
       "      <td>0.50975</td>\n",
       "      <td>...</td>\n",
       "      <td>4617.40</td>\n",
       "      <td>0.214890</td>\n",
       "      <td>0.223520</td>\n",
       "      <td>0.78761</td>\n",
       "      <td>0.27412</td>\n",
       "      <td>6.2791</td>\n",
       "      <td>6.1622</td>\n",
       "      <td>103.630</td>\n",
       "      <td>3.5220</td>\n",
       "      <td>1.9673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.652610</td>\n",
       "      <td>0.148120</td>\n",
       "      <td>1.2628</td>\n",
       "      <td>29.071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.53230</td>\n",
       "      <td>1.2891</td>\n",
       "      <td>0.34739</td>\n",
       "      <td>...</td>\n",
       "      <td>920.98</td>\n",
       "      <td>0.045169</td>\n",
       "      <td>0.023421</td>\n",
       "      <td>0.99434</td>\n",
       "      <td>0.14403</td>\n",
       "      <td>22.7480</td>\n",
       "      <td>2.2673</td>\n",
       "      <td>159.580</td>\n",
       "      <td>2.2872</td>\n",
       "      <td>4.4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045396</td>\n",
       "      <td>0.279640</td>\n",
       "      <td>0.708730</td>\n",
       "      <td>3.7656</td>\n",
       "      <td>238.120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056710</td>\n",
       "      <td>2.57610</td>\n",
       "      <td>1.0169</td>\n",
       "      <td>0.72036</td>\n",
       "      <td>...</td>\n",
       "      <td>10744.00</td>\n",
       "      <td>0.047501</td>\n",
       "      <td>0.063019</td>\n",
       "      <td>0.94624</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.8860</td>\n",
       "      <td>49.0660</td>\n",
       "      <td>91.984</td>\n",
       "      <td>3.9681</td>\n",
       "      <td>29.0460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_1    feat_2    feat_3   feat_4   feat_5    feat_6    feat_7  \\\n",
       "0  0.279320  0.053105  0.852030  17.0440  199.080  0.741770  0.353570   \n",
       "1  0.001871  0.735120  0.156460   1.2269  -10.837  0.000000  0.002938   \n",
       "2  0.113940  0.490250  0.077121   1.2332  -43.184 -0.000171  0.113940   \n",
       "3  0.008136  0.652610  0.148120   1.2628   29.071  0.000000  0.008136   \n",
       "4  0.045396  0.279640  0.708730   3.7656  238.120  0.000000  0.056710   \n",
       "\n",
       "     feat_8  feat_9  feat_10  ...   feat_55   feat_56   feat_57  feat_58  \\\n",
       "0  16.00600  1.2346  0.84997  ...  52857.00  0.190040  0.328630  0.80996   \n",
       "1   0.36032  1.4809  0.26488  ...    440.02  0.014794  0.007064  0.99803   \n",
       "2   1.03980  1.1649  0.50975  ...   4617.40  0.214890  0.223520  0.78761   \n",
       "3   0.53230  1.2891  0.34739  ...    920.98  0.045169  0.023421  0.99434   \n",
       "4   2.57610  1.0169  0.72036  ...  10744.00  0.047501  0.063019  0.94624   \n",
       "\n",
       "   feat_59  feat_60  feat_61  feat_62  feat_63  feat_64  \n",
       "0  0.00000      NaN   4.1858   11.002  33.1760  18.5720  \n",
       "1  0.00000   7.4268   2.2925  169.960   2.1476   9.6185  \n",
       "2  0.27412   6.2791   6.1622  103.630   3.5220   1.9673  \n",
       "3  0.14403  22.7480   2.2673  159.580   2.2872   4.4718  \n",
       "4  0.00000  13.8860  49.0660   91.984   3.9681  29.0460  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "print(\"X_train_over shape:\", X_train_over.shape)\n",
    "X_train_over.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "First I'll calculate the baseline accuracy.\n",
    "\n",
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9519\n"
     ]
    }
   ],
   "source": [
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate\n",
    "Even though the building blocks are the same with the previous notebook, here's where I start working with something new. First, I'm going to use a new type of ensemble model for our classifier.\n",
    "\n",
    "Ensemble models are machine learning models that use more than one predictor to arrive at a prediction. A group of predictors form an _ensemble_. In general, ensemble models perform better than using a single predictor. There are three types of ensemble models: **bagging**, **boosting**, and **blending**. Of the three, decision trees are commonly used to construct bagging and boosting models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting trees is another ensemble model. It uses a collection of tree models arranged in a sequence. Here, the model is built stage-wise; each additional tree aims to correct the previous tree's incorrect. \n",
    "\n",
    "Where does the name *gradient* in gradient boosting trees come from? Gradient descent is a minimization algorithm that updates/improves the current answer by taking a step in the direction of minimizing the loss function. This is the same as the gradient boosting trees algorithm as it adds trees to minimize loss/improve model performance. The term **boosting** refers to the algorithm's ability to combine multiple weak models in sequence to form a stronger model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting trees have a similar set of hyperparameters as random forests but with some key additions.\n",
    "\n",
    "<table>\n",
    "\t<tr>\n",
    "    <th style=\"text-align: left\">Hyperparameter</th>\n",
    "    <th style=\"text-align: left\">Description</th>\n",
    "\t</tr>  \n",
    "    <tr>\n",
    "        <td style=\"text-align: left\"><code>learning_rate</code></td>\n",
    "        <td style=\"text-align: left\">Multiplicative factor of the tree's contribution to the model.</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left\"><code>subsample</code></td>\n",
    "        <td style=\"text-align: left\">Fraction of the training data to use when fitting the trees.</td>\n",
    "\t</tr>\n",
    "</table>\n",
    "\n",
    "The learning rate determines how much each tree affect the final outcome and is very important in model convergence. Thus it should be considered during hyperparameter tuning to improve model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll Create a pipeline named `clf` (short for \"classifier\") that contains a `SimpleImputer` transformer and a `GradientBoostingClassifier` predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(SimpleImputer(), GradientBoostingClassifier())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm doing this because I only want to be to be looking at the positive class. Here, the positive class is the one where the companies really did go bankrupt.\n",
    "\n",
    "I'll be tuning some of the hyperparameters next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simpleimputer__strategy': ['mean', 'median'],\n",
       " 'gradientboostingclassifier__n_estimators': range(20, 31, 5),\n",
       " 'gradientboostingclassifier__max_depth': range(2, 5)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with the range of hyperparameters that we want to evaluate for our classifier.\n",
    "params = {\n",
    "    \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"gradientboostingclassifier__n_estimators\": range(20, 31, 5),\n",
    "    \"gradientboostingclassifier__max_depth\": range(2, 5)\n",
    "}\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV named model that includes your classifier and hyperparameter grid.\n",
    "model = GridSearchCV(clf, param_grid=params, cv=5, n_jobs=1,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                                       (&#x27;gradientboostingclassifier&#x27;,\n",
       "                                        GradientBoostingClassifier())]),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gradientboostingclassifier__max_depth&#x27;: range(2, 5),\n",
       "                         &#x27;gradientboostingclassifier__n_estimators&#x27;: range(20, 31, 5),\n",
       "                         &#x27;simpleimputer__strategy&#x27;: [&#x27;mean&#x27;, &#x27;median&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                                       (&#x27;gradientboostingclassifier&#x27;,\n",
       "                                        GradientBoostingClassifier())]),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;gradientboostingclassifier__max_depth&#x27;: range(2, 5),\n",
       "                         &#x27;gradientboostingclassifier__n_estimators&#x27;: range(20, 31, 5),\n",
       "                         &#x27;simpleimputer__strategy&#x27;: [&#x27;mean&#x27;, &#x27;median&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer()),\n",
       "                (&#x27;gradientboostingclassifier&#x27;, GradientBoostingClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                                       ('gradientboostingclassifier',\n",
       "                                        GradientBoostingClassifier())]),\n",
       "             n_jobs=1,\n",
       "             param_grid={'gradientboostingclassifier__max_depth': range(2, 5),\n",
       "                         'gradientboostingclassifier__n_estimators': range(20, 31, 5),\n",
       "                         'simpleimputer__strategy': ['mean', 'median']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model to over-sampled training data\n",
    "model.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gradientboostingclassifier__max_depth</th>\n",
       "      <th>param_gradientboostingclassifier__n_estimators</th>\n",
       "      <th>param_simpleimputer__strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.785408</td>\n",
       "      <td>0.162590</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.930240</td>\n",
       "      <td>0.913129</td>\n",
       "      <td>0.913458</td>\n",
       "      <td>0.925962</td>\n",
       "      <td>0.911455</td>\n",
       "      <td>0.918849</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.644468</td>\n",
       "      <td>0.050552</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.915762</td>\n",
       "      <td>0.897006</td>\n",
       "      <td>0.909181</td>\n",
       "      <td>0.915762</td>\n",
       "      <td>0.911455</td>\n",
       "      <td>0.909833</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.011922</td>\n",
       "      <td>0.101110</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.916749</td>\n",
       "      <td>0.899638</td>\n",
       "      <td>0.898322</td>\n",
       "      <td>0.909181</td>\n",
       "      <td>0.895655</td>\n",
       "      <td>0.903909</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.992399</td>\n",
       "      <td>0.246169</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.906219</td>\n",
       "      <td>0.889108</td>\n",
       "      <td>0.895031</td>\n",
       "      <td>0.897993</td>\n",
       "      <td>0.902238</td>\n",
       "      <td>0.898118</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.286886</td>\n",
       "      <td>0.152849</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.901941</td>\n",
       "      <td>0.888450</td>\n",
       "      <td>0.884501</td>\n",
       "      <td>0.896677</td>\n",
       "      <td>0.872284</td>\n",
       "      <td>0.888771</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.283405</td>\n",
       "      <td>0.217841</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 4, '...</td>\n",
       "      <td>0.892399</td>\n",
       "      <td>0.878578</td>\n",
       "      <td>0.885160</td>\n",
       "      <td>0.879237</td>\n",
       "      <td>0.883476</td>\n",
       "      <td>0.883770</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.601521</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.874630</td>\n",
       "      <td>0.877591</td>\n",
       "      <td>0.869365</td>\n",
       "      <td>0.866074</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.873693</td>\n",
       "      <td>0.169094</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.862126</td>\n",
       "      <td>0.864758</td>\n",
       "      <td>0.858506</td>\n",
       "      <td>0.857519</td>\n",
       "      <td>0.855826</td>\n",
       "      <td>0.859747</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.769110</td>\n",
       "      <td>0.170987</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>median</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.863442</td>\n",
       "      <td>0.858506</td>\n",
       "      <td>0.846331</td>\n",
       "      <td>0.862126</td>\n",
       "      <td>0.850889</td>\n",
       "      <td>0.856259</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.198209</td>\n",
       "      <td>0.076996</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'gradientboostingclassifier__max_depth': 3, '...</td>\n",
       "      <td>0.848634</td>\n",
       "      <td>0.844686</td>\n",
       "      <td>0.847318</td>\n",
       "      <td>0.844357</td>\n",
       "      <td>0.853851</td>\n",
       "      <td>0.847769</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "16       5.785408      0.162590         0.006818        0.001318   \n",
       "17       5.644468      0.050552         0.007281        0.002567   \n",
       "14       5.011922      0.101110         0.007421        0.001645   \n",
       "15       4.992399      0.246169         0.006954        0.000530   \n",
       "12       4.286886      0.152849         0.007072        0.001104   \n",
       "13       4.283405      0.217841         0.005722        0.000398   \n",
       "10       4.601521      0.022702         0.005891        0.000330   \n",
       "8        3.873693      0.169094         0.005792        0.000454   \n",
       "11       4.769110      0.170987         0.006729        0.001118   \n",
       "6        3.198209      0.076996         0.005949        0.000660   \n",
       "\n",
       "   param_gradientboostingclassifier__max_depth  \\\n",
       "16                                           4   \n",
       "17                                           4   \n",
       "14                                           4   \n",
       "15                                           4   \n",
       "12                                           4   \n",
       "13                                           4   \n",
       "10                                           3   \n",
       "8                                            3   \n",
       "11                                           3   \n",
       "6                                            3   \n",
       "\n",
       "   param_gradientboostingclassifier__n_estimators  \\\n",
       "16                                             30   \n",
       "17                                             30   \n",
       "14                                             25   \n",
       "15                                             25   \n",
       "12                                             20   \n",
       "13                                             20   \n",
       "10                                             30   \n",
       "8                                              25   \n",
       "11                                             30   \n",
       "6                                              20   \n",
       "\n",
       "   param_simpleimputer__strategy  \\\n",
       "16                          mean   \n",
       "17                        median   \n",
       "14                          mean   \n",
       "15                        median   \n",
       "12                          mean   \n",
       "13                        median   \n",
       "10                          mean   \n",
       "8                           mean   \n",
       "11                        median   \n",
       "6                           mean   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "16  {'gradientboostingclassifier__max_depth': 4, '...           0.930240   \n",
       "17  {'gradientboostingclassifier__max_depth': 4, '...           0.915762   \n",
       "14  {'gradientboostingclassifier__max_depth': 4, '...           0.916749   \n",
       "15  {'gradientboostingclassifier__max_depth': 4, '...           0.906219   \n",
       "12  {'gradientboostingclassifier__max_depth': 4, '...           0.901941   \n",
       "13  {'gradientboostingclassifier__max_depth': 4, '...           0.892399   \n",
       "10  {'gradientboostingclassifier__max_depth': 3, '...           0.874630   \n",
       "8   {'gradientboostingclassifier__max_depth': 3, '...           0.862126   \n",
       "11  {'gradientboostingclassifier__max_depth': 3, '...           0.863442   \n",
       "6   {'gradientboostingclassifier__max_depth': 3, '...           0.848634   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "16           0.913129           0.913458           0.925962   \n",
       "17           0.897006           0.909181           0.915762   \n",
       "14           0.899638           0.898322           0.909181   \n",
       "15           0.889108           0.895031           0.897993   \n",
       "12           0.888450           0.884501           0.896677   \n",
       "13           0.878578           0.885160           0.879237   \n",
       "10           0.877591           0.869365           0.866074   \n",
       "8            0.864758           0.858506           0.857519   \n",
       "11           0.858506           0.846331           0.862126   \n",
       "6            0.844686           0.847318           0.844357   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "16           0.911455         0.918849        0.007705                1  \n",
       "17           0.911455         0.909833        0.006898                2  \n",
       "14           0.895655         0.903909        0.007877                3  \n",
       "15           0.902238         0.898118        0.005888                4  \n",
       "12           0.872284         0.888771        0.010258                5  \n",
       "13           0.883476         0.883770        0.004980                6  \n",
       "10           0.866359         0.870804        0.004580                7  \n",
       "8            0.855826         0.859747        0.003245                8  \n",
       "11           0.850889         0.856259        0.006610                9  \n",
       "6            0.853851         0.847769        0.003438               10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the cross-validation results from model and load them into a DataFrame named cv_results.\n",
    "results = pd.DataFrame(model.cv_results_)\n",
    "results.sort_values(\"rank_test_score\").head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's quite a few hyperparameters here, so I'll pull out the ones that work best for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingclassifier__max_depth': 4,\n",
       " 'gradientboostingclassifier__n_estimators': 30,\n",
       " 'simpleimputer__strategy': 'mean'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract best hyperparameters\n",
    "model.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9265\n",
      "Validation Accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "# calculate the training and test accuarcy scores for the model\n",
    "acc_train = model.score(X_train_over, y_train_over)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Validation Accuracy:\", round(acc_test, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, I'll  make a confusion matrix to see how the model is making its correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1913\n",
       "True       83\n",
       "Name: bankrupt, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix is a great reminder of how imbalanced the data is, and of why accuracy isn't always the best metric for judging whether or not a model is giving us what we want. After all, if 95% of the companies in the dataset didn't go bankrupt, all the model has to do is always predict `{\"bankrupt\": False}`, and it'll be right 95% of the time. The accuracy score will be amazing, but it won't tell us what we really need to know.\n",
    "\n",
    "Instead, I can evaluate the model using two new metrics: **precision** and **recall**.  The precision score is important when we want our model to only predict that a company will go bankrupt if its very confident in its prediction. The *recall* score is important if we want to make sure to identify all the companies that will go bankrupt, even if that means being incorrect sometimes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.89      0.93      1913\n",
      "        True       0.22      0.76      0.35        83\n",
      "\n",
      "    accuracy                           0.88      1996\n",
      "   macro avg       0.61      0.82      0.64      1996\n",
      "weighted avg       0.96      0.88      0.91      1996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model, using the test set.\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision for the false class is 0.99, which means that when the model predicts a company is not bankrupt, it is correct 99% of the time. The recall for the false class is 0.89, which means that when a company is actually not bankrupt, the model correctly identifies it 89% of the time.\n",
    "\n",
    "The precision for the True class \"1\" is 0.22, which means that when the model predicts a company is bankrupt, it is correct 22% of the time. The recall for the true class is 0.76, which means that the model identifies 76% of the bankrupt companies correctly.\n",
    "\n",
    "The F1-score is a weighted harmonic mean of precision and recall. The F1-score for the false class is 0.93, indicating a high level of accuracy, while the F1-score for the true class is 0.35, indicating that the model's performance is relatively poor for this class.\n",
    "\n",
    "The overall accuracy of the model is 0.88, meaning that it correctly identifies the class of a company 88% of the time. The macro average F1-score is 0.64, which provides a balanced view of the model's performance across both classes. The weighted average F1-score is 0.91, taking into account the fact that the negative class \"0\" has a much larger number of samples than the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cd30d9e7354970bc395302a537038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, continuous_update=False, description='Threshold:', max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca54571a5074630b8c3280252f33334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(height='300px', width='300px')), VBox(children=(Output(layout=Layout(heighâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ConfusionMatrixWidget(model, X_test, y_test)\n",
    "c.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll create an interactive dashboard that shows how company profit and losses change in relationship to the model's probability threshold. Starting with the make_cnf_matrix function, which should calculate and print profit/losses, and displaying a confusion matrix. Then I'll create a FloatSlider thresh_widget that ranges from 0 to 1. And then finally I'll combine the function and slider in the interact function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you move the probability threshold, you can see that there's a tradeoff between precision and recall. That is, as one gets better, the other suffers. As a data scientist, you'll often need to decide whether you want a model with better precision or better recall. What you choose will depend on how to intend to use your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aea4927d3d44b66a57f0f5de1b3f4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='threshold', max=1.0, step=0.05), Output()), _dom_claâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_cnf_matrix(threshold):\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, -1]\n",
    "    y_pred = y_pred_proba > threshold\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    print(f\"Profit:  â‚¬{tp * 100_000_000}\")\n",
    "    print(f\"Losses:  â‚¬{tp * 250_000_000}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, colorbar=False)\n",
    "\n",
    "\n",
    "thresh_widget = widgets.FloatSlider(min=0, max=1, value=0.5, step=0.05)\n",
    "\n",
    "interact(make_cnf_matrix, threshold=thresh_widget);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a context manager, save the best-performing model to a file named \"gradient_boosting.pkl\".\n",
    "with open(\"gradient_boosting.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
